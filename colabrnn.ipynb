{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colabrnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/demmojo/colabrnn/blob/master/colabrnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ZwEWNRf8ZEOi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train your own text generator using a recurrent neural network!\n",
        "by [Mohamed Abdulaziz](https://www.mohamedabdulaziz.com/)\n",
        "\n",
        "Train either a bidirectional or normal LSTM recurrent neural network to generate text using any dataset.  **No need to write any code. Just upload your text file and click run!**\n",
        "\n",
        "You can generate text after your model has finished training as well! Also you can continue training a pre-trained model if it needs more accuracy.\n",
        "\n",
        "**The best part is that all of the training is conducted on a free GPU courtesy of Colaboratory!**\n",
        "\n",
        "For more information about the code used in this demo please check this github link.[github link](https://github.com/demmojo/colabrnn)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rimi-EESvGVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Before you begin\n",
        "\n",
        "Ensure you are running this in Google Chrome. \n",
        "\n",
        "Next, copy the notebook to your Google Drive to keep it as well as save your changes. \n",
        "\n",
        "Also, make sure you are using the GPU runtime type by clicking **Runtime** in the toolbar above and then **Change runtime type**. Check if the hardware accelerator is set to GPU.\n",
        "\n",
        "That's it! Run the next code cells!\n"
      ]
    },
    {
      "metadata": {
        "id": "At7H0K4Qe7SY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/demmojo/colabrnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBoHbZnTfl3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above code clones the github project on the Colaboratory VM. Next we will install the dependencies and import the necessary packages."
      ]
    },
    {
      "metadata": {
        "id": "EobyzRjoK_c5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: If you get a **Failed to assign a backend** message that means that no free GPUs are available. You can connect and train using CPUs but that will be much slower. Otherwise, try again later to connect to a server with a GPU. "
      ]
    },
    {
      "metadata": {
        "id": "SrzkCSSEcjsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras==2.2\n",
        "\n",
        "from google.colab import files\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j7cqqjbhsi3v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# What would you like to do?\n",
        "\n",
        "If you are training a new model we first need to upload a text file. Then colabrnn will use that to train and generate original text! \n",
        "\n",
        "## Train a new model\n",
        "\n",
        "Run the cell below and click ***Choose Files*** and select your files from your local computer. (Ideally, your text files should be quite large >1mb).\n",
        "\n",
        "Please note that the uploaded file is stored on the Colaboratory VM and** only you** have access to it.\n",
        "\n",
        "After uploading the file run the next cell to start the training process! You can see generated text as the training process goes on to see how your model is learning.\n",
        "\n",
        "If you prefer to change some parameters please do so before running the cell.\n",
        "\n",
        "## Continue training a pre-trained model\n",
        "\n",
        "Run the cell below and upload the weight, vocabulary and config files as well as the text file.\n",
        "\n",
        "After uploading the necessary model files (weight, vocabulary and config files) as well as the text file you can retrain your old model. \n",
        "\n",
        "Change the ***train_new_model*** variable to **False**. Then check whether the file names are correct before running the cell below.\n",
        "\n",
        "## Generate text with a pre-trained model\n",
        "\n",
        "After uploading the necessary model files (weight, vocabulary and config files) as well as the text file skip to the section: **Generate text using your trained model**.\n",
        "\n",
        "Check whether the file names are correct before running the cell."
      ]
    },
    {
      "metadata": {
        "id": "UR2vf0nG_e2V",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "d0cd2f2d-5ec5-43fb-cd89-32376edd6e10"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "latest_uploaded_file = sorted(all_files, key=lambda x: -x[1])[0][0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-09d3cd37-9a45-4cf7-a0cb-9e4755c3e718\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-09d3cd37-9a45-4cf7-a0cb-9e4755c3e718\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1rQ4lFinceov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from colabrnn.rnn import CharGen\n",
        "from colabrnn.rnn.train_model import train\n",
        "\n",
        "train_new_model = True\n",
        "model_name = 'colab'\n",
        "\n",
        "if train_new_model:  # Create a new neural network model and train it\n",
        "    char_gen = CharGen(name=model_name)\n",
        "    train(text_filepath=latest_uploaded_file,\n",
        "          chargen=char_gen,\n",
        "          gen_text_length=500,  # Number of characters to be generated. Average number of characters in a word is approximately 5. (default 500)\n",
        "          num_epochs=10,  # One epoch is when an entire dataset is passed forward and backward through the neural network only once (default 10)\n",
        "          bidirectional=False,  # Boolean. Train using a bidirectional LSTM or unidirectional LSTM. See this coursera video for more information: https://www.coursera.org/lecture/nlp-sequence-models/bidirectional-rnn-fyXnn\n",
        "          rnn_size=128,  # Number of neurons in each layer of your neural network (default 128)\n",
        "          rnn_layers=3,  # Number of layers in your neural network (default 3)\n",
        "          batch_size=512,  # Total number of training examples present in a single batch. More is faster but there are memory constraints. If you are experiencing insufficient memory issues reduce this number. (default 512)\n",
        "          embedding_dims=75,  # Size of the embedding layer\n",
        "          train_new_model=train_new_model)  \n",
        "\n",
        "    print(char_gen.model.summary())\n",
        "else:  # Continue training an old model\n",
        "    text_filename = 'shakespeare.txt'  # specify correct filename if you are retraining an old model\n",
        "    char_gen = CharGen(name=model_name,\n",
        "                      weights_filepath='colab_weights.hdf5',  # specify correct filename if you are retraining an old model\n",
        "                      vocab_filepath='colab_vocabulary.json',  # specify correct filename if you are retraining an old model\n",
        "                      config_filepath='colab_config.json')  # specify correct filename if you are retraining an old model\n",
        "    \n",
        "    train(text_filename, char_gen, train_new_model=train_new_model, num_epochs=10)  # change num_epochs to specify number of epochs to continue training\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QizcSnyvzGdR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the model files\n",
        "\n",
        "Run the cell below to save the model files locally. You can upload them again later to retrain."
      ]
    },
    {
      "metadata": {
        "id": "CmmApybl3Btl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocabulary.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4HTTjr1rzYV9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate text using your trained model!\n",
        "\n",
        "Run the cell below to generate samples of your trained model. \n",
        "\n",
        "You can specify the starting text  for the model by changing the ***prefix***  variable to use as the beginning of the generated text.\n",
        "\n",
        "You can also define how long you want your generated text to be by ***change gen_text_length*** variable.\n",
        "\n",
        "Have fun!"
      ]
    },
    {
      "metadata": {
        "id": "U_ioCslUzp21",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from colabrnn.rnn import CharGen\n",
        "\n",
        "char_gen = CharGen(weights_filepath='colab_weights.hdf5',  # specify correct filename \n",
        "                   vocab_filepath='colab_vocabulary.json',  # specify correct filename\n",
        "                   config_filepath='colab_config.json')  # specify correct filename \n",
        "\n",
        "char_gen.generate(gen_text_length=500, prefix='To be or not to be,')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICV_FdOe6kvi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If at any time you would like to list the contents of the current directory use the following command:"
      ]
    },
    {
      "metadata": {
        "id": "14YJm4Hv1g41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bfaa2fe0-eae6-48e7-cfc0-79eb26c8e26b"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colab_config.json  colab_vocabulary.json  datalab\r\n",
            "colabrnn\t   colab_weights.hdf5\t  shakespeare.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1MlAlHP_L0eE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "910T4lEU6yhm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you would like to restart or reset the Colaboratory VM you can run the following cell:"
      ]
    },
    {
      "metadata": {
        "id": "MRe7rzwzrUus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEqZBUMp7J3f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### If you have any questions, suggestions or would like to share your project, please contact me [here](https://www.mohamedabdulaziz.com/#contact).\n",
        "\n",
        "### You can also check out my other projects on [Github](https://github.com/demmojo)."
      ]
    }
  ]
}